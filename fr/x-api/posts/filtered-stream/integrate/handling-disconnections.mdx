---
title: Gestion des déconnexions
sidebarTitle: Gestion des déconnexions
---

### Qu&#39;est-ce qu&#39;une déconnexion ?

Établir une connexion aux API de streaming consiste à effectuer une requête HTTPS de très longue durée et à analyser la réponse au fil de l&#39;eau. Lors de la connexion à l’endpoint de flux filtré, vous devez émettre une requête HTTPS et consommer le flux obtenu aussi longtemps que possible. Nos serveurs maintiendront la connexion ouverte indéfiniment, sauf en cas d’erreur côté serveur, de latence excessive côté client, de problèmes réseau, de maintenance serveur courante ou de connexions en double. Avec les connexions aux endpoints de streaming, il est probable — et normal — que des déconnexions se produisent ; une logique de reconnexion doit donc être prévue.
 

<div id="why-a-streaming-connection-might-be-disconnected">
  #### Pourquoi une connexion de streaming peut être interrompue
</div>

Votre flux peut se déconnecter pour plusieurs raisons. Consultez le message d’erreur renvoyé par le flux pour comprendre la cause de l’échec. Les raisons possibles de déconnexion sont les suivantes :

* Une erreur d’authentification (par exemple, un jeton invalide ou une méthode d’authentification inappropriée).
* Un serveur de streaming redémarre côté X. C’est généralement lié à un déploiement et doit être anticipé et pris en compte dans la conception.
* Votre client n’arrive pas à suivre le volume de publications délivré par le flux ou lit les données trop lentement. Chaque connexion de streaming s’appuie sur une file d’attente de messages à envoyer au client. Si cette file d’attente devient trop importante, la connexion sera fermée.
* Votre compte a dépassé son quota quotidien/mensuel de publications.
* Vous avez trop de connexions redondantes actives.
* Le client cesse soudainement de lire les données. Si le débit de lecture des publications depuis le flux chute brusquement, la connexion sera fermée.
* Problèmes réseau possibles entre le serveur et le client.
* Un problème temporaire côté serveur, une maintenance ou une mise à jour planifiée. (Consultez la [page d’état](https://api.twitterstat.us/))
   

#### Erreurs de déconnexion courantes : 

```{
	"errors": [{
		"title": "operational-disconnect",
		"disconnect_type": "UpstreamOperationalDisconnect",
		"detail": "Ce flux a été déconnecté en amont pour des raisons opérationnelles.",
		"type": "https://api.x.com/2/problems/operational-disconnect"
	}]
}
```

```
{
	"title": "ConnectionException",
	"detail": "Ce flux a atteint la limite maximale de connexions autorisées.",
	"connection_issue": "TooManyConnections",
	"type": "https://api.x.com/2/problems/streaming-connection"
}
```

<div id="anticipating-disconnects-and-reconnecting">
  #### Anticiper les déconnexions et se reconnecter
</div>

Lors de la diffusion en continu de Posts, l’objectif est de rester connecté le plus longtemps possible, tout en sachant que des déconnexions peuvent survenir. L’endpoint envoie un signal de keep-alive toutes les 20 secondes (il se présente comme un caractère de nouvelle ligne). Utilisez ce signal pour détecter une éventuelle déconnexion.

1. Votre code doit détecter lorsque le contenu récent et le keep-alive cessent d’arriver.
2. Le cas échéant, votre code doit déclencher une logique de reconnexion. Certains clients et langages vous permettent de spécifier un délai d’expiration de lecture, que vous pouvez définir à 20 secondes.
3. Votre service doit détecter ces déconnexions et se reconnecter dès que possible.

Une fois qu’une connexion établie est interrompue, tentez de vous reconnecter immédiatement. Si la reconnexion échoue, ralentissez vos tentatives en fonction du type d’erreur rencontré :

* Adoptez un backoff linéaire pour les erreurs réseau au niveau TCP/IP. Ces problèmes sont généralement temporaires et se résolvent rapidement. Augmentez le délai entre les reconnexions de 250 ms à chaque tentative, jusqu’à 16 secondes.
* Adoptez un backoff exponentiel pour les erreurs HTTP pour lesquelles une reconnexion est appropriée. Commencez par une attente de 5 secondes, en la doublant à chaque tentative, jusqu’à 320 secondes.
* Adoptez un backoff exponentiel pour les erreurs HTTP 429 (limite de taux dépassée). Commencez par une attente de 1 minute et doublez à chaque tentative. Notez que chaque HTTP 429 reçu augmente le temps d’attente avant que la limitation de taux ne soit plus appliquée à votre compte.
   

<div id="recovering-lost-data">
  #### Récupérer les données perdues
</div>

En cas de déconnexion, plusieurs stratégies peuvent vous aider à récupérer toutes les données que vous auriez pu manquer. Nous avons documenté les étapes clés pour retrouver les données manquées dans notre guide d’intégration consacré à la [récupération des données](/fr/x-api/posts/filtered-stream/integrate/recovery-and-redundancy-features). 
 

<div id="rate-limits-and-usage">
  #### Limites de débit et utilisation
</div>

Pour vérifier les limites, la réponse renverra trois en-têtes. Cela vous aide à comprendre combien de fois vous pouvez utiliser le point de terminaison des règles et combien de tentatives de reconnexion sont autorisées pour le point de terminaison de streaming.

* x-rate-limit-limit indique le nombre de requêtes autorisées pour votre client sur une fenêtre de 15 minutes.

* x-rate-limit-remaining indique le nombre de requêtes effectuées jusqu’à présent dans la fenêtre de 15 minutes.

* x-rate-limit-reset est un horodatage UNIX indiquant le moment où la fenêtre de 15 minutes redémarre, réinitialisant x-rate-limit-remaining à 0.

Le point de terminaison de flux filtré ne signale actuellement pas de données d’utilisation. Pour vérifier combien de Posts ont été livrés, votre code peut implémenter une logique de comptage, afin que la consommation puisse être mesurée et mise en pause si nécessaire.

Le code côté client de votre flux insère simplement les Posts entrants dans une file d’attente « premier entré, premier sorti » (FIFO), ou une structure mémoire similaire ; un processus/thread séparé doit consommer les Posts de cette file pour les analyser et préparer le contenu pour le stockage. Avec cette conception, vous pouvez mettre en place un service qui s’adapte efficacement si les volumes de Posts entrants varient fortement. Conceptuellement, vous pouvez l’imaginer comme le téléchargement d’un fichier infiniment long via HTTP.

<div id="reconnection-best-practices">
  #### Bonnes pratiques de reconnexion
</div>

**Tester les stratégies d’atténuation (backoff)**

Une bonne manière de tester une implémentation de backoff consiste à utiliser des identifiants d’autorisation invalides et à observer les tentatives de reconnexion. Une implémentation correcte ne doit recevoir aucune réponse 429.

**Déclencher des alertes en cas de reconnexions multiples**

Si un client atteint sa limite supérieure d’intervalle entre les reconnexions, il doit vous envoyer des notifications afin que vous puissiez prioriser et traiter les problèmes affectant votre connexion.

**Gérer les changements de DNS**

Vérifiez que votre processus client respecte la valeur Time To Live (TTL) du DNS. Certaines piles mettent en cache une adresse résolue pendant toute la durée du processus et ne tiennent pas compte des changements DNS dans le TTL prescrit. Un tel cache agressif entraînera des interruptions de service côté client lorsque X répartit la charge entre des adresses IP.

**User-Agent**

Assurez-vous que l’en-tête HTTP User-Agent inclut la version du client. Cela sera essentiel pour diagnostiquer les problèmes côté X. Si votre environnement ne permet pas de définir le champ User-Agent, définissez un en-tête x-user-agent.