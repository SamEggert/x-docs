---
title: API Decahose
---

<Note>
  Cet endpoint a été mis à jour pour inclure les métadonnées d’édition de posts. Pour en savoir plus sur ces métadonnées, consultez la page des principes de base [&quot;Modifier des posts&quot;](/fr/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets). 
</Note>

<div id="decahose-stream">
  ### Flux Decahose
</div>

[Enterprise](https://developer.x.com/en/products/x-api/enterprise)

*Ceci est une API Enterprise disponible uniquement dans nos niveaux d’accès gérés. Pour utiliser cette API, vous devez d’abord ouvrir un compte avec notre équipe commerciale Enterprise. [En savoir plus](https://developer.x.com/en/products/x-api/enterprise)*

Le Decahose livre un échantillon aléatoire de 10 % du Firehose X en temps réel via une connexion de streaming. Cela est réalisé au moyen d’un algorithme d’échantillonnage en temps réel qui sélectionne les données de façon aléatoire, tout en préservant la latence faible attendue lors de l’envoi des données dans le firehose par X.

Voici quelques-unes des fonctionnalités disponibles avec Decahose :

* **URL étendues et enrichies :** - déroule entièrement les URL raccourcies et fournit des métadonnées supplémentaires (titre et description de la page)
* **Partitionnement du flux** - 2 partitions, chacune contenant 50 % du volume du flux Decahose
* **Fiabilité améliorée** - diversité géographique des systèmes backend

Remarque : ces données sont livrées en vrac et ne prennent pas en charge de filtrage supplémentaire (par exemple, par mots-clés).

`ENTERPRISE`

<div id="streaming-likes">
  ### Flux de likes
</div>

*Ceci est une API Entreprise disponible uniquement dans nos niveaux d’accès gérés. Pour utiliser cette API, vous devez d’abord ouvrir un compte avec notre équipe commerciale Enterprise. [En savoir plus](https://developer.x.com/en/products/x-api/enterprise)*

Les likes offrent de la visibilité sur qui aime des Posts et fournissent des comptages précis des likes. Gnip Firehose et Decahose peuvent livrer les likes publics liés aux Posts fournis via Gnip. Cela fournit des métriques d’engagement public en temps réel et des indicateurs d’audience associés à un Post.
 

**Premiers pas avec les likes**

Avant de consommer des données de likes, sachez que :

* Les likes sont livrés via un flux indépendant, distinct
* Historiquement, les likes étaient appelés « Favorites ». La charge utile au format natif enrichi conserve cette nomenclature
* Les flux n’incluent que les likes publics
  * Public signifie que l’utilisateur qui like, le créateur du Post et le Post sont tous publics sur la plateforme
* Les likes sont très proches des Retweets et représentent un signal public d’engagement
* Les éléments de la charge utile incluent :
  * L’objet Post original
  * L’objet Actor qui a créé le Post original
  * L’objet Actor qui a effectué l’action de like
* Seul le contenu original peut être liké
  * Les Retweets ne peuvent pas être likés. Un like d’un Retweet est appliqué au Post original
  * Les Quoted Tweets *peuvent* être likés
* Les activités de like incluent les Gnip Enrichments applicables (lorsqu’ils sont achetés/appliqués)
* Produits / fonctionnalités pris en charge
  * Les flux de likes prennent en charge le Backfill (lorsqu’il est acheté/appliqué)
  * Il n’y a pas de prise en charge Replay pour les flux de likes
  * Il n’y a pas de prise en charge Search ou Historical pour les likes
  * Il n’y a pas de projet immédiat d’ajouter la prise en charge des likes à PowerTrack

**Decahose**

* Pour l’échantillon de 10 % des Posts livré dans Decahose, le flux inclut 100 % des likes publics applicables
* **Partitions :** 2
* **Structure d’URL**
  * https://gnip-stream.x.com/stream/sample10-likes/accounts/&lt;accountName&gt;/publishers/twitter/&lt;streamLabel&gt;.json?partition=1

**Charge utile au format natif enrichi**

```json
{
   "id":"43560406e0ad9f68374445f5f30c33fc",
   "created_at":"Thu Dec 01 22:27:39 +0000 2016",
   "timestamp_ms":1480631259353,
   "favorited_status":{
      "created_at":"Thu Dec 01 22:27:16 +0000 2016",
      "id":804451830033948672,
      "id_str":"804451830033948672",
      "text":"@kafammheppduman",
      "source":"\u003ca href=\"http:\/\/x.com\/download\/android\" rel=\"nofollow\"\u003eX pour Android\u003c\/a\u003e",
      "truncated":false,
      "in_reply_to_status_id":803694205163814912,
      "in_reply_to_status_id_str":"803694205163814912",
      "in_reply_to_user_id":2855759795,
      "in_reply_to_user_id_str":"2855759795",
      "in_reply_to_screen_name":"kafammheppduman",
      "user":{
         "id":2855759795,
         "id_str":"2855759795",
         "name":"delirdim kanka",
         "screen_name":"kafammheppduman",
         "location":"sanane",
         "url":"http:\/\/instagram.com\/kafammheppduman",
         "description":"Fan @GalatasaraySk \ud83d\udc9e",
         "translator_type":"none",
         "protected":false,
         "verified":false,
         "followers_count":3702,
         "friends_count":607,
         "listed_count":1,
         "favourites_count":113338,
         "statuses_count":389,
         "created_at":"Sat Nov 01 22:38:25 +0000 2014",
         "utc_offset":null,
         "time_zone":null,
         "geo_enabled":true,
         "lang":"tr",
         "contributors_enabled":false,
         "is_translator":false,
         "profile_background_color":"C0DEED",
         "profile_background_image_url":"",
         "profile_background_image_url_https":"",
         "profile_background_tile":false,
         "profile_link_color":"1DA1F2",
         "profile_sidebar_border_color":"C0DEED",
         "profile_sidebar_fill_color":"DDEEF6",
         "profile_text_color":"333333",
         "profile_use_background_image":true,
       "Profile_image_url": "http:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "Profile_image_url_https": "https:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "profile_banner_url":"https:\/\/pbs.twimg.com\/profile_banners\/2855759795\/1480630085",
         "default_profile":true,
         "default_profile_image":false,
         "following":null,
         "follow_request_sent":null,
         "notifications":null
      },
      "geo":null,
      "coordinates":null,
      "place":null,
      "contributors":null,
      "is_quote_status":false,
      "retweet_count":0,
      "favorite_count":0,
      "entities":{
         "hashtags":[],
         "urls":[],
         "user_mentions":[
            {
               "screen_name":"kafammheppduman",
               "name":"delirdim kanka",
               "id":2855759795,
               "id_str":"2855759795",
               "indices":[
                  0,
                  16
               ]
            }
         ],
         "symbols":[]
      },
      "favorited":false,
      "retweeted":false,
      "filter_level":"faible",
      "lang":"und"
   },
   "user":{
      "id":774146932365070336,
      "id_str":"774146932365070336",
      "name":"Uyuyan Adam",
      "screen_name":"saykoMenn",
      "location":"Tarsus, T\u00fcrkiye",
      "url":"http:\/\/connected2.me\/pmc1i",
      "description":null,
      "translator_type":"none",
      "protected":false,
      "verified":false,
      "followers_count":414,
      "friends_count":393,
      "listed_count":0,
      "favourites_count":9868,
      "statuses_count":370,
      "created_at":"Fri Sep 09 07:26:26 +0000 2016",
      "utc_offset":null,
      "time_zone":null,
      "geo_enabled":false,
      "lang":"tr",
      "contributors_enabled":false,
      "is_translator":false,
      "profile_background_color":"F5F8FA",
      "profile_background_image_url":"",
      "profile_background_image_url_https":"",
      "profile_background_tile":false,
      "profile_link_color":"1DA1F2",
      "profile_sidebar_border_color":"C0DEED",
      "profile_sidebar_fill_color":"DDEEF6",
      "profile_text_color":"333333",
      "profile_use_background_image":true,
      "profile_image_url": "http:\/\/pbs.twimg.com\/profile_images\/802992813424201728\/VMzcTL3x_normal.jpg",
      "profile_image_url_https": "https:\/\/pbs.twimg.com\/profile_images\/802992813424201728\/VMzcTL3x_normal.jpg",
      "profile_banner_url":"https:\/\/pbs.twimg.com\/profile_banners\/774146932365070336\/1480283382",
      "default_profile":true,
      "default_profile_image":false,
      "following":null,
      "follow_request_sent":null,
      "notifications":null
   }
}
```

**Payload de suppression de J’aime / « Retrait du J’aime »**

```json
{
   "delete":{
      "favorite":{
         "tweet_id":696615514970279937,
         "tweet_id_str":"696615514970279937",
         "user_id":2510287578,
         "user_id_str":"2510287578"
      },
      "timestamp_ms":"1480437031205"
   }
}
```

<div id="guides">
  ## Guides
</div>

<div id="recovery-and-redundency">
  ### Récupération et redondance
</div>

**Introduction** 

Le streaming de forts volumes de Posts en temps réel s’accompagne d’un ensemble de bonnes pratiques qui favorisent à la fois la fiabilité et l’exhaustivité des données. Lors de la consommation de données en temps réel, maximiser le temps de connexion est un objectif essentiel. En cas de déconnexion, il est important de la détecter automatiquement et de se reconnecter. Après la reconnexion, il convient d’évaluer s’il existe des périodes pour lesquelles effectuer un rattrapage de données. Le composant qui gère ces aspects et consomme les Posts en temps réel n’est qu’une partie d’un système qui implique le réseau, les datastores, les serveurs et le stockage. Compte tenu de la complexité de ces systèmes, une autre bonne pratique consiste à disposer de différents environnements de streaming, avec au minimum des flux distincts pour le développement/test et la production.

Decahose propose un ensemble de fonctionnalités qui facilitent ces efforts.

1. Pour gérer plusieurs environnements, nous pouvons déployer des [Additional Streams](#AdditionalStreams) pour votre compte. Ces flux sont indépendants les uns des autres et disposent d’un stream&#95;label différent pour les distinguer.
2. Pour aider à maintenir la connexion, chaque flux Decahose prend en charge des [Redundant Connections](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#additional-streams). L’architecture la plus courante consiste à doter un flux de deux connexions et, côté client, de deux consommateurs indépendants – idéalement sur des réseaux différents. Avec cette conception, la redondance couvre les réseaux côté client, les serveurs et les chemins vers les datastores. Notez qu’une copie complète des données est fournie sur chaque connexion et que le client doit tolérer et gérer les doublons.
3. Un « heartbeat » est envoyé toutes les 10 secondes ; cependant, avec le flux Decahose, le volume de données est suffisamment élevé pour que même une courte période (p. ex. quelques secondes) sans Posts puisse indiquer un problème de connexion. Par conséquent, à la fois un « silence de données » et l’absence de heartbeat peuvent être utilisés pour détecter une déconnexion.

Étant donné que des déconnexions se produiront, le flux Decahose propose des fonctionnalités dédiées de [Recovery](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#overview) et de [Backfill](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#backfill) pour aider à récupérer les données manquées en raison de déconnexions et d’autres incidents opérationnels.

<div id="additional-streams">
  #### Flux supplémentaires
</div>

Disposer de flux Decahose supplémentaires est un autre moyen d’intégrer de la fiabilité à votre solution. Tous les flux supplémentaires sont entièrement indépendants, chacun disposant de son propre endpoint. Chaque flux se voit attribuer son propre stream&#95;label, et cette étiquette, avec votre nom de compte, fait partie de l’URL de ce flux. Voir l’exemple ci-dessous :

https://gnip-stream.x.com/stream/sample10/accounts/:account&#95;name/publishers/twitter/:stream&#95;label.json

La convention la plus courante consiste à disposer d’un flux temps réel dédié à votre système de production, et d’un flux supplémentaire disponible pour le développement et les tests. Disposer d’un flux de test/de développement permet aux clients Decahose de tester les mises à jour de leurs consommateurs client. Bien que toute étiquette (unique) puisse être attribuée à un flux, une convention consiste à utiliser « prod » pour le flux de production, et « dev » ou « sandbox » pour un flux de développement supplémentaire.

Le nombre de flux, et leurs étiquettes uniques, est configurable par votre représentant de compte.

**Connexions redondantes**

Une connexion redondante vous permet simplement d’établir plus d’une connexion simultanée au flux de données. Cela apporte de la redondance en vous permettant de vous connecter au même flux avec deux consommateurs distincts, et de recevoir les mêmes données via les deux connexions. Ainsi, votre application dispose d’un basculement à chaud pour diverses situations, par exemple lorsqu’un flux est déconnecté ou lorsque le serveur principal de votre application tombe en panne.

Le nombre de connexions autorisées pour un flux donné est configurable par votre représentant de compte. Pour utiliser une connexion redondante, connectez-vous simplement à la même URL que celle utilisée pour votre connexion principale. Les données de votre flux seront envoyées via les deux connexions, lesquelles seront toutes deux visibles sur le tableau de bord du flux.

Notez qu’à des fins de facturation, nous dédupliquons les décomptes d’activités que vous recevez via plusieurs connexions, de sorte que vous ne soyez facturé qu’une seule fois pour chaque activité unique. Étant donné que le Decahose comporte deux partitions, voici un exemple du fonctionnement du décompte des connexions :

Connect to decahose partition=1
Connect to decahose partition=1
Connect to decahose partition=2

La situation ci-dessus donne un total de trois connexions — deux connexions à partition=1 et une connexion à partition=2. Normalement, vous souhaiteriez le même nombre de connexions pour chaque partition ; cet exemple met donc en évidence une situation où la connexion redondante à partition=2 est tombée et nécessite une investigation plus poussée.

**Récupération**

#### Aperçu 

Recovery est un outil de récupération de données (à ne pas utiliser pour la collecte de données principale) qui offre un accès en continu à une fenêtre glissante de 5 jours des données historiques récentes de X. Il doit être utilisé pour récupérer des données lorsque votre application consommatrice manque des éléments dans le flux en temps réel, que ce soit en raison d’une brève déconnexion ou de tout autre cas où vous n’avez pas pu ingérer des données en temps réel pendant un certain temps.

<div id="using-recovery">
  #### Utilisation de Recovery
</div>

Avec le flux Recovery, votre application peut lui adresser des requêtes qui fonctionnent de la même manière que celles destinées aux flux en temps réel. Cependant, votre application doit spécifier dans l’URL des paramètres indiquant la fenêtre temporelle demandée. En d’autres termes, une requête Recovery demande à l’API « des Posts de l’instant A à l’instant B ». Ces Posts sont ensuite livrés via votre connexion de streaming d’une façon qui imite le flux en temps réel, mais à un rythme légèrement inférieur au temps réel. Voir l’exemple ci-dessous :

&quot;https://stream-data-api.x.com/stream/powertrack/accounts/someAccountName/publishers/twitter/powertrack.json?startTime=2023-07-05T17:09:12.070Z&quot;

Les Posts sont livrés en commençant par la première (la plus ancienne) minute de la période spécifiée, puis en continuant chronologiquement jusqu’à la dernière minute. À ce moment-là, un message Recovery Request Completed est envoyé via la connexion, puis la connexion est fermée par le serveur. Si votre requête commence à une heure de la journée où peu ou pas de résultats correspondants se sont produits, un certain délai peut s’écouler avant la livraison des premiers résultats — les données seront livrées lorsque Recovery rencontrera des correspondances dans la portion de l’archive alors en cours de traitement. Lorsqu’aucun résultat n’est disponible, le flux continue d’envoyer des retours chariot, ou « heartbeats », via la connexion afin d’éviter tout dépassement de délai.

Recovery est conçu comme un outil permettant de récupérer facilement des données manquées en raison de courtes déconnexions, et non pour de très longues périodes comme une journée entière. Si vous devez récupérer des données sur de longues périodes, nous recommandons de diviser les requêtes plus longues en fenêtres temporelles plus courtes (par exemple deux heures) afin de réduire le risque de déconnexion en cours de requête dû à la volatilité d’Internet ou à d’autres raisons, et pour offrir une meilleure visibilité sur l’avancement des requêtes longues.

<div id="data-availability">
  #### Disponibilité des données
</div>

Vous pouvez utiliser la fonctionnalité Recovery pour récupérer les données manquées au cours des dernières 24 heures si vous n’êtes pas en mesure de vous reconnecter dans la fenêtre de rattrapage de 5 minutes.

La fonctionnalité de récupération en streaming vous offre une fenêtre de rattrapage étendue de 24 heures. Recovery vous permet de « récupérer » la période de données manquées. Un flux de récupération est lancé lorsque vous effectuez une requête de connexion en utilisant les paramètres &#39;start&#95;time&#39; et &#39;end&#95;time&#39;. Une fois connecté, Recovery retransmet la période indiquée, puis se déconnecte.

Vous pouvez effectuer 2 requêtes Recovery simultanées, c’est‑à‑dire « deux tâches de récupération ». Recovery fonctionne techniquement de la même manière que le rattrapage, sauf qu’une heure de début et une heure de fin sont définies. Une période de récupération correspond à une seule plage temporelle.

<div id="backfill">
  #### Rétroremplissage
</div>

Pour demander un rétroremplissage, vous devez ajouter le paramètre backfillMinutes=N à votre requête de connexion, où N est le nombre de minutes (1 à 5, nombres entiers uniquement) à rétroremplir lors de l’établissement de la connexion. Par exemple, si vous êtes déconnecté pendant 90 secondes, vous devez ajouter backfillMinutes=2 à votre requête de connexion. Étant donné que cette requête fournira un rétroremplissage de 2 minutes, y compris pour les 30 secondes précédant votre déconnexion, votre *application consommatrice doit tolérer les doublons*.

Exemple d’URL de requête de connexion Decahose demandant un rétroremplissage de 5 minutes vers la partition 1 :

https://gnip-stream.x.com/stream/sample10/accounts/:account&#95;name/publishers/twitter/:stream&#95;label.json?partition=1&amp;backfillMinutes=5

**REMARQUES :**

* Vous pouvez choisir d’utiliser systématiquement « backfillMinutes=5 » lors de la connexion, puis de gérer les éventuelles données en double.

* Si vous êtes déconnecté plus de cinq minutes, vous pouvez récupérer les données à l’aide de Recovery.

**Récupération après déconnexion**

Redémarrer et se remettre d’une déconnexion implique plusieurs étapes :

* Déterminer la durée de la période de déconnexion.
  * 5 minutes ou moins ?
    * Si le rétroremplissage est activé pour le flux, préparez la requête de connexion avec le paramètre « backfillMinutes » approprié.
  * Plus de 5 minutes ?
    * Si vous disposez d’un flux Recovery, effectuez une requête Recovery pour la période de déconnexion (idéalement avec votre jeu de règles temps réel actuel, en utilisant l’API Rules si nécessaire).
* Demander une nouvelle connexion.

Lorsque vous rencontrez des déconnexions ou des interruptions, voici des stratégies pour atténuer l’impact et vous rétablir :

1. **Mettre en œuvre le rétroremplissage**
   Le rétroremplissage vous permet de vous reconnecter à partir d’un point antérieur à la déconnexion d’un flux et couvre des déconnexions allant jusqu’à 5 minutes. Il s’active en incluant un paramètre dans la requête de connexion.

2. **Consommer un flux redondant depuis un autre emplacement**
   Si le flux redondant peut être injecté dans le même environnement de production en direct, avec déduplication des données, vous éliminerez le besoin de récupération sauf si LE flux normal ET le flux redondant subissent simultanément une interruption ou une déconnexion. Si le flux redondant ne peut pas être diffusé en direct dans l’environnement de production, il peut être écrit dans un magasin de données « d’urgence » distinct. Ainsi, en cas de déconnexions ou d’interruptions sur la connexion de flux principale, votre système disposera des données nécessaires pour compléter votre base de données principale sur la période manquante.

3. **Mettre en œuvre Recovery**
   Lorsque des déconnexions ou des interruptions affectent à la fois le flux principal et le flux redondant, utilisez Decahose Recovery pour récupérer toute donnée manquée. L’API fournit une fenêtre glissante couvrant 5 jours d’archives, à exploiter de préférence en demandant au maximum une heure de cette fenêtre à la fois, puis en la diffusant. Cela se fait en parallèle du flux temps réel. Notez que nous ne proposons pas de solution pour récupérer des données Decahose au-delà de la fenêtre de 5 jours fournie par Recovery ; il est donc important d’utiliser un flux redondant pour vous assurer de disposer d’une copie complète des données de votre côté en cas d’interruption significative.

Lorsque vous détectez des volumes de données stockées anormaux –
Façons possibles de détecter des données manquantes alors qu’aucune déconnexion ou interruption ne s’est produite…

1. Compter les Posts entrants
   Votre système doit compter le nombre brut de Posts que vous recevez dès le tout début de votre application d’ingestion, puis fournir un moyen de comparer ces nombres avec le nombre de Posts qui atteignent votre magasin de données final. Toute divergence peut être surveillée et alerter votre équipe sur des problèmes causant la perte de données après leur réception.

2. Analyser les volumes stockés anormaux
   Vous pouvez également analyser les volumes de données stockées dans votre base de données finale pour rechercher des baisses anormales. Cela peut également indiquer des problèmes, bien qu’il y ait probablement des circonstances dans lesquelles des baisses de volume sont normales (par exemple, si la plateforme X est indisponible et que les personnes ne peuvent pas créer de Posts pendant un certain temps).

<div id="api-reference">
  ## Référence API
</div>

<div id="decahose-stream">
  ### Flux Decahose
</div>

Aller à cette section

[Méthodes](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#methods)

[Authentification](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#authentication)

[GET /&#123;stream-type&#125;/:stream](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#get-stream-type-stream)

[API de relecture](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#replay-api)

<div id="methods">
  #### Méthodes
</div>

| Méthode | Description |
| :--- | :--- |
| [GET /&#123;stream-type&#125;/:stream](#Stream) | Connexion au flux de données |

<div id="authentication">
  #### Authentication[](#authentication- "Permalink to this headline")
</div>

Toutes les requêtes adressées aux APIs Volume Stream doivent utiliser l’authentification HTTP Basic, établie à partir d’une adresse e-mail et d’un mot de passe valides utilisés pour vous connecter à votre compte sur console.gnip.com. Les identifiants doivent être transmis dans l’en-tête Authorization pour chaque requête. Assurez-vous donc que votre client ajoute l’en-tête HTTP &quot;Authorization: Basic&quot; (avec des identifiants encodés via HTTPS) à toutes les requêtes API.

#### GET {stream-type}:stream

Établit une connexion persistante au flux Firehose, via laquelle les données en temps réel seront délivrées.

<div id="request-specifications">
  #### Spécifications de la requête
</div>

|     |     |
| :--- | :--- |
| **Méthode de requête** | HTTP GET |
| **Type de connexion** | Keep-Alive  <br />  <br />Ceci doit être spécifié dans l&#39;en-tête de la requête. |
| **URL** | Disponible sur la page d&#39;aide API du flux de votre tableau de bord, en utilisant la structure suivante :  <br />  <br />Decahose :<br /><br />[https://gnip-stream.x.com/stream/sample10/accounts/:account&#95;name/publishers/twitter/:stream&#95;label.json?partition=1](https://gnip-stream.x.com/stream/sample10/accounts/:account_name/publishers/twitter/:stream_label.json?partition=1) |
| **Partition (obligatoire)** | `partition=\{#}` - Le partitionnement est désormais obligatoire pour consommer l&#39;intégralité du flux. Vous devrez vous connecter au flux avec le paramètre de partition spécifié. Voici le nombre de partitions par flux :<br /><br />* Decahose : 2 partitions |
| **Compression** | Gzip. Pour vous connecter au flux en utilisant la compression Gzip, envoyez simplement un en-tête Accept-Encoding dans la requête de connexion. L&#39;en-tête doit ressembler à ceci :  <br />  <br />Accept-Encoding: gzip |
| **Encodage des caractères** | UTF-8 |
| **Format de réponse** | JSON. L&#39;en-tête de votre requête doit spécifier le format JSON pour la réponse. |
| **Limite de débit** | 10 requêtes par 60 secondes. |
| **Paramètre de rattrapage** | Si vous avez acheté un flux avec le rattrapage activé, vous devrez ajouter le paramètre &quot;backfillMinutes&quot; dans la requête GET pour l&#39;activer. |
| **Délai d&#39;expiration de lecture** | Définissez un délai d&#39;expiration de lecture sur votre client et assurez-vous qu&#39;il soit défini sur une valeur supérieure à 30 secondes. |
| **Prise en charge des modifications de Tweet** | Tous les objets Tweet incluront les métadonnées de modification de Tweet décrivant l&#39;historique de modification du Tweet. Consultez la [page des fondamentaux &quot;Modifier les Tweets&quot;](/fr/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets) pour plus de détails. |

<div id="responses">
  #### Réponses
</div>

Les réponses suivantes peuvent être renvoyées par l’API pour ces requêtes. La plupart des codes d’erreur sont accompagnés d’une chaîne avec des détails supplémentaires dans le corps. Pour toute réponse différente de 200, les clients doivent tenter de se reconnecter.

| Statut | Texte | Description |
| :--- | :--- | :--- |
| 200 | Réussite | La connexion a été ouverte avec succès et les nouvelles activités seront transmises au fur et à mesure de leur arrivée. |
| 401 | Non autorisé | L’authentification HTTP a échoué en raison d’identifiants invalides. Connectez-vous à console.gnip.com avec vos identifiants pour vérifier que vous les utilisez correctement dans votre requête. |
| 406 | Non acceptable | En général, cela se produit lorsque votre client n’inclut pas correctement les en-têtes indiquant l’acceptation de l’encodage gzip pour le flux, mais cela peut également survenir dans d’autres cas.  <br />  <br />Contiendra un message JSON similaire à « Cette connexion nécessite une compression. Pour activer la compression, envoyez un en-tête ‘Accept-Encoding: gzip’ dans votre requête et préparez-vous à décompresser le flux lors de sa lecture côté client. » |
| 429 | Limitation de débit | Votre application a dépassé la limite de requêtes de connexion. |
| 503 | Service indisponible | Problème côté serveur Twitter. Reconnectez-vous en appliquant un backoff exponentiel. Si aucun avis concernant ce problème n’a été publié sur la [X API Status Page](https://api.twitterstat.us/), contactez le support ou l’assistance d’urgence si vous ne parvenez pas à vous connecter après 10 minutes. |

<div id="example-curl-request">
  #### Exemple de requête cURL
</div>

L&#39;exemple de requête suivant est exécuté avec cURL en ligne de commande. Notez toutefois que vous pouvez également envoyer ces requêtes dans le langage de programmation de votre choix :

```
curl --compressed -v -uexample@customer.com "https://gnip-stream.x.com/stream/firehose/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition={#}"
```

<div id="replay-api">
  #### API Replay
</div>

L’API Replay est un complément essentiel aux flux de volume en temps réel. Replay est un outil de récupération de données qui fournit un accès en streaming à une fenêtre glissante des données historiques récentes de X.